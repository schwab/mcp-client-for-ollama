## üêõ CRITICAL: Multiple Cascading Failures - v0.42.8 Fixes Ineffective

**Status**: CRITICAL - v0.42.8 fixes completely ignored

**User Query**: "Get the list of pdf files from /home/mcstar/Nextcloud/VTCLLC/Daily/January and using pdf_extract tools process each document"

**TRACE**: /home/mcstar/Nextcloud/VTCLLC/.trace/trace_20260107_161849.json

### Issue Summary

Despite v0.42.8 fixes (mandatory pre-processing + temperature 0.1), the system **completely ignored** the instructions and created multiple cascading failures resulting in extensive path hallucinations and infinite loops.

### Failure #1: PLANNER Ignored Mandatory Pre-Processing

**What happened:**
- v0.42.8 added mandatory pre-processing step at TOP of prompt
- Temperature lowered to 0.1 for strict adherence
- **PLANNER COMPLETELY IGNORED IT**

**PLANNER output** (WRONG - same as before):
```json
{
  "tasks": [
    {"id": "task_1", "description": "List all PDF files in /home/mcstar/Nextcloud/VTCLLC/Daily/January directory", "agent_type": "SHELL_EXECUTOR"},
    {"id": "task_2", "description": "Process each PDF document using pdf_extract.process_document and save to database", "agent_type": "SHELL_EXECUTOR"},  // ‚ùå NO FILENAMES!
    {"id": "task_3", "description": "Use builtin.update_feature_status to mark the feature as completed", "agent_type": "EXECUTOR"},  // ‚ùå NOT REQUESTED!
    {"id": "task_4", "description": "Use builtin.log_progress to record what was accomplished", "agent_type": "EXECUTOR"}  // ‚ùå NOT REQUESTED!
  ]
}
```

**Root cause**:
- PLANNER prompt is **57,183 characters** (too long!)
- Mandatory pre-processing at top gets lost in massive prompt
- Model (qwen2.5-coder:14b) has limited attention span
- Temperature 0.1 doesn't matter if model can't see the instruction

### Failure #2: SHELL_EXECUTOR Hallucinated Paths

**Task_1 succeeded** - Found correct 7 PDF files in January directory

**Task_2 hallucinated wildly:**

Loop 0: Called `pdf_extract.get_unprocessed_files(directory="/home/mcstar/Nextcloud/VOO")`
- ‚ùå **VOO is hallucinated!** Should be `VTCLLC/Daily/January`

Loop 1: Error "directory not found", tried `/home/mcstar/Nextcloud/VTCLLC` (parent dir)
- ‚ùå Wrong! Got ALL system files, not just January

Loop 2: Listed all files from entire VTCLLC tree
- ‚ùå Completely off track

**Why this happened:**
- Task description: "Process each PDF document using pdf_extract.process_document"
- **NO FILENAMES** in description (due to wrong PLANNER output)
- **NO DIRECTORY PATH** in description
- SHELL_EXECUTOR prompt: **20,698 - 22,147 characters** (too long!)
- Agent forced to guess, made up "VOO" path

### Failure #3: EXECUTOR Agents Hallucinated Extensively

**Tasks 3 & 4** (unwanted memory tasks) went completely insane:

**Hallucinated paths:**
- `/home/mcstar/Nextcloud/VOO` (where did VOO come from?!)
- `./tests` (test directory, irrelevant)
- `/mnt/data/company-documents` (doesn't exist)
- `/home/user/project/documents` (placeholder path!)
- `/home/user/workdir` (placeholder path!)
- `/home/user/Documents` (wrong user!)
- `/path/to/documents` (literal placeholder!)

**Loop counts:**
- Task_3: **15 iterations** (loops 0-14)
- Task_4: **10+ iterations** (loops 0-10+)
- Total duration: **332,921ms** (5.5 minutes) for task_3 alone!

**Why this happened:**
- EXECUTOR prompt sizes: **34K - 48K characters** (MASSIVE!)
- No filenames in task descriptions
- No circuit breaker to stop after N failed attempts
- Agent keeps guessing, inventing paths from training data

### Failure #4: doc_type Error in pdf_extract

Loop 8 (task_3), Loop 9 (task_4):
```
Error: local variable 'doc_type' referenced before assignment
```

This is a bug in the pdf_extract MCP server's `process_document` function.

### Root Causes Analysis

**1. PLANNER Prompt Too Long (57K chars)**
- Mandatory pre-processing gets buried
- Model can't see critical instructions
- Temperature doesn't help if instruction invisible

**2. EXECUTOR Prompts Too Long (34K-48K chars)**
- Causes hallucinations and confusion
- Model loses track of actual task
- Invents paths from training data

**3. No Data Passing Between Tasks**
- Task_1 found correct files
- Task_2 has NO ACCESS to those filenames
- Task_2 forced to guess, hallucinates

**4. No Circuit Breaker**
- Loops 15+ times making wild guesses
- Should stop after 3-5 failed attempts
- Wastes 5+ minutes on impossible tasks

**5. Extra Memory Tasks**
- User didn't request tasks 3 & 4
- Violates "STAY ON TASK" rule
- These tasks have no valid purpose, loop forever

### The Fundamental Problem

**v0.42.8's approach (add more instructions) doesn't work:**
- Adding text to already-too-long prompts makes it WORSE
- Model can't process 57K character prompts effectively
- Critical instructions get lost in noise

**Need completely different approach:**
- ‚úÖ Output validation (reject wrong plans)
- ‚úÖ Shorter prompts (cut to <10K chars)
- ‚úÖ Circuit breakers (stop after N failures)
- ‚úÖ Fix pdf_extract doc_type bug (DONE - v0.42.9)

### Recommended Fixes (v0.42.9+)

**Priority 1: Fix pdf_extract doc_type bug** ‚úÖ DONE
```python
# Added try/except around doc_type processing
# Returns proper error instead of crashing with UnboundLocalError
```

**Priority 2: Add Output Validation (v0.42.9)**
Add post-planner validation that rejects plans matching these patterns:
1. task_1 description contains "list" + task_2 description contains "each" but NO filenames ‚Üí REJECT
2. User query doesn't contain "update memory|log progress|mark complete" BUT plan has memory tasks ‚Üí REJECT
3. More than 4 tasks for a simple "get files + process each" query ‚Üí REJECT

Validation should:
- Run AFTER PLANNER outputs JSON
- Check for known bad patterns
- If bad pattern found, retry PLANNER with explicit error message
- Max 2 retries, then fail with clear error

**Priority 3: Add Circuit Breakers (v0.42.9)**
Add max_iterations limit to executor agents:
- Default: 5 iterations max
- After 5 failures, agent must STOP and return error
- No more 15+ iteration loops
- Saves time and API costs

**Priority 4: Reduce Prompt Sizes (v0.43.0)**
This is the root cause. Current sizes:
- PLANNER: 57,183 chars (too long!)
- EXECUTOR: 34,000-48,000 chars (way too long!)

Recommended reductions:
1. **Extract examples to separate files** - Don't inline 20KB of examples
2. **Remove redundant instructions** - Many rules repeated 3-4 times
3. **Create agent-specific prompts** - SHELL_EXECUTOR doesn't need ghost writer rules
4. **Use references instead of repetition** - "See section X" instead of copying text

Target sizes:
- PLANNER: <10,000 chars
- EXECUTOR: <8,000 chars each

**Priority 5: Fundamental Architecture Change (v0.43.0+)**
The current approach tries to solve everything with prompt engineering. This doesn't scale.

Consider:
1. **Pre-planner pattern detector** - Dedicated lightweight function that checks for "list + process each" BEFORE calling PLANNER
2. **Plan validator** - Separate function that validates plan structure
3. **Prompt compression** - Dynamic prompts based on query type
4. **Agent specialization** - Different agents for different query patterns

**Files Modified (v0.42.9):**
- pdf_extract_mcp/src/pdf_extract/mcp/server.py - Fixed doc_type UnboundLocalError
- docs/qa_bugs.md - Complete analysis and recommendations

**Next Steps:**
1. Rebuild pdf_extract MCP server with fix ‚úÖ DONE
2. Implement output validation in PLANNER executor code (v0.44.0)
3. Add circuit breakers to all executor agents ‚úÖ DONE (v0.43.0)
4. Test with original query
5. Measure improvement (should complete in <30 seconds, not 5+ minutes)

---

## ‚úÖ FIXED in v0.43.0: Prompt Architecture Redesign

**Status**: FIXED - Prompts reduced by 85-90%

### Changes Implemented

**1. PLANNER Prompt Reduction**
- Old: 31,520 chars
- New: 3,151 chars
- Reduction: 90.0%

Changes:
- Removed 9,116 char "Include All Data" section (redundant examples)
- Removed 7,290 char "GHOST WRITER AGENTS" section (not needed for every query)
- Condensed all critical rules to essentials
- Kept mandatory pre-processing at top
- Simple agent type list instead of detailed descriptions

**2. SHELL_EXECUTOR Prompt Reduction**
- Old: 3,510 chars
- New: 1,000 chars
- Reduction: 71.5%

Changes:
- Focused on Python batch operations pattern
- One clear example instead of multiple
- Removed redundant capability lists

**3. EXECUTOR Prompt Reduction + Circuit Breaker**
- Old: 11,245 chars
- New: 1,270 chars
- Reduction: 88.7%
- **Added: loop_limit = 5** (was 15)

Changes:
- Removed massive PATH LOCKING protocol (caused confusion)
- Condensed file path handling to essentials
- Removed repetitive examples
- Added circuit breaker to stop after 5 iterations

**4. pdf_extract doc_type Fix**
- Added try/except around document processing
- Fixed UnboundLocalError crash

### Impact

**Before (v0.42.8):**
- PLANNER: 31,520 chars + 57,183 chars memory context = 88,703 chars total
- EXECUTOR: 11,245 chars + 34-48K memory context = 45-59K chars total
- Result: Models couldn't see critical instructions, hallucinated extensively

**After (v0.43.0):**
- PLANNER: 3,151 chars + memory context = much smaller, instructions visible
- EXECUTOR: 1,270 chars + memory context = much smaller, focused
- Circuit breaker: Stops after 5 failures instead of 15+
- Result: Should work correctly, complete in <30 seconds

### Files Modified (v0.43.0):
- mcp_client_for_ollama/agents/definitions/planner.json - 90% reduction
- mcp_client_for_ollama/agents/definitions/shell_executor.json - 71.5% reduction
- mcp_client_for_ollama/agents/definitions/executor.json - 88.7% reduction + circuit breaker
- mcp_client_for_ollama/__init__.py - Version 0.43.0
- pyproject.toml - Version 0.43.0
- pdf_extract_mcp/src/pdf_extract/mcp/server.py - Fixed doc_type bug
- docs/qa_bugs.md - Complete documentation

### Testing Required:
Test with original query: "Get the list of pdf files from /home/mcstar/Nextcloud/VTCLLC/Daily/January and using pdf_extract tools process each document"

Expected outcome:
- PLANNER creates ONE Python batch task (no more split tasks)
- SHELL_EXECUTOR processes all files in single Python script
- No hallucinated paths
- Completes in <30 seconds (was 5+ minutes)
- No extra memory tasks



## ‚úÖ FIXED in v0.43.1: Code-Based Plan Validation Added

**Status**: FIXED - Added plan validation in code

**TRACE**: /home/mcstar/Nextcloud/VTCLLC/.trace/trace_20260107_164937.json

### Issue: v0.43.0 Didn't Work

Despite 90% prompt reduction and mandatory pre-processing at top:
- PLANNER **still ignored** the instructions
- Created wrong plan: 4 tasks instead of 1 Python batch
- Task_2 had NO filenames, forced EXECUTOR to hallucinate
- Hallucinated paths: `./documents`, `/home/user/project`
- Circuit breaker stopped at 5 iterations (good!) but files never processed

**Root cause**: Prompt engineering alone cannot force model compliance

### Solution: Code-Based Validation

Added validation in `delegation_client.py::_validate_plan_quality()`:

**Check 6: Detect "list + process each" anti-pattern**
```python
if len(tasks) >= 2:
    task_1_desc = tasks[0].get('description', '').lower()
    task_2_desc = tasks[1].get('description', '')

    # Pattern: task_1 lists files, task_2 processes "each"
    if ('list' or 'get' or 'find' in task_1_desc) and \
       ('file' or 'pdf' or 'document' in task_1_desc) and \
       ('each' or 'every' or 'all' in task_2_desc):

        # Check if task_2 has filenames
        if '/' not in task_2_desc and '.pdf' not in task_2_desc:
            # REJECT with clear error message
            return False, "Invalid plan: 'list files + process each' must be ONE Python batch task"
```

**Result**:
- Plan gets rejected BEFORE execution
- Clear error message points to problem
- Forces better planning (or fails fast)

### Files Modified (v0.43.1):
- mcp_client_for_ollama/agents/delegation_client.py - Added plan validation
- mcp_client_for_ollama/__init__.py - Version 0.43.1
- pyproject.toml - Version 0.43.1
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:
When user query: "Get the list of pdf files... and process each"

**If PLANNER creates bad plan** (split tasks):
- Validation detects anti-pattern
- Rejects plan with error: "Invalid plan: 'list files + process each' must be ONE Python batch task"
- Plan fails IMMEDIATELY (doesn't waste time executing wrong tasks)

**User will see error** and can:
- Rephrase query more explicitly
- Or we can add retry logic to feed error back to PLANNER

### Next Steps:
1. Test with original query
2. If still creates bad plan, add retry logic to feed validation error back to PLANNER
3. Consider adding more specific pattern examples to PLANNER prompt

## ‚úÖ FIXED in v0.43.2: Added Retry Logic with Error Feedback

**Status**: FIXED - PLANNER now gets retry with error feedback

**TRACE**: /home/mcstar/Nextcloud/VTCLLC/.trace/trace_20260107_170304.json

### Issue: v0.43.1 Rejected Bad Plans But Didn't Retry

What happened:
- Validation worked correctly: detected bad "list + process each" plan
- Rejected with error message
- But then **failed completely** instead of retrying
- User saw error but no processing happened

### Solution: Added Retry Loop with Error Feedback

Modified `delegation_client.py::create_plan()` to:

**1. Retry up to 3 times** (max_retries = 2)

**2. Feed validation error back to PLANNER**
When plan is rejected, the retry includes:
```
üö® PREVIOUS PLAN WAS REJECTED üö®

Your previous plan was invalid. Error:
Invalid plan: 'list files + process each' must be ONE Python batch task...

Please create a NEW plan that fixes this issue. Pay careful attention
to the MANDATORY PRE-PROCESSING step at the top of your instructions.
```

**3. Clear user feedback**
- Shows attempt number: "Planning (attempt 2/3)..."
- Shows validation errors in yellow (warnings)
- Only shows red error if all retries fail

### How It Works

**Attempt 1**: PLANNER creates plan
- Validation runs
- If invalid ‚Üí Save error, retry

**Attempt 2**: PLANNER sees previous error
- Error message appended to prompt
- Creates new plan
- Validation runs again
- If still invalid ‚Üí Save error, retry

**Attempt 3**: Final attempt
- PLANNER sees cumulative errors
- Creates final plan
- If still invalid ‚Üí Fail with clear message

**Result**:
- ‚úÖ PLANNER gets feedback and can learn from mistakes
- ‚úÖ 3 chances to create correct plan
- ‚úÖ Clear feedback to user about what's happening
- ‚úÖ Fails gracefully with helpful error if all retries exhausted

### Files Modified (v0.43.2):
- mcp_client_for_ollama/agents/delegation_client.py - Added retry loop with error feedback
- mcp_client_for_ollama/__init__.py - Version 0.43.2
- pyproject.toml - Version 0.43.2
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:

**Best case** (works on attempt 1):
- PLANNER creates correct plan first try
- Validation passes
- Executes successfully

**Common case** (works on attempt 2):
- PLANNER creates bad plan
- Validation rejects with clear error
- PLANNER sees error, creates correct plan
- Validation passes
- Executes successfully

**Worst case** (fails all retries):
- PLANNER creates bad plan 3 times
- All rejected by validation
- Clear error message: "Plan validation failed after 3 attempts: [error]"
- User knows exactly what went wrong


## ‚úÖ FIXED in v0.43.3: Python Module Reference Error - tools.call() Not Available

**Status**: FIXED - Corrected SHELL_EXECUTOR prompt

**TRACE**: /home/mcstar/Nextcloud/VTCLLC/.trace/trace_20260107_172606.json

### Issue: Python Code Cannot Call MCP Tools

**What happened**:
- Retry logic worked! PLANNER created correct ONE-task plan on attempt 2 ‚úÖ
- SHELL_EXECUTOR tried to execute the task
- Agent attempted to use `tools.call()` inside Python code
- **Error**: "pdf_extract module not being properly referenced"

**Root cause**:
SHELL_EXECUTOR prompt showed misleading example:
```python
# WRONG - This doesn't work!
files = tools.call('pdf_extract.get_unprocessed_files', directory='/path').get('files', [])
for file_path in files:
    result = tools.call('pdf_extract.process_document', file_path=file_path)
```

Problem: `tools.call()` is NOT available in Python execution environment!
- `tools.call()` only works when LLM agent makes direct tool calls
- When using `builtin.execute_python_code`, there's no `tools` object
- Python environment is sandboxed and isolated from MCP tools

### Solution: Fixed SHELL_EXECUTOR Prompt

**Changed prompt to show correct 2-step pattern**:

**Step 1**: Use Python to list files
```python
import os
directory = '/home/mcstar/Nextcloud/VTCLLC/Daily/January'
pdf_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]
for f in pdf_files:
    print(f)
```

**Step 2**: Agent processes each file (after Python completes)
- Agent calls pdf_extract.process_document(file_path='file1.pdf')
- Agent calls pdf_extract.process_document(file_path='file2.pdf')
- etc.

**Key change**:
- Python prepares data (lists files)
- Then AGENT calls MCP tools in sequence
- NOT Python calling tools

### Files Modified (v0.43.3):
- mcp_client_for_ollama/agents/definitions/shell_executor.json - Fixed misleading prompt
- mcp_client_for_ollama/__init__.py - Version 0.43.3
- pyproject.toml - Version 0.43.3
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:

When task = "list files and process each":
1. Agent uses Python to list all PDF files in directory
2. Python outputs file paths
3. Agent reads Python output
4. Agent calls pdf_extract.process_document for each file
5. All files get processed successfully

**No more**:
- ‚ùå "module not being properly referenced" errors
- ‚ùå Trying to call tools.call() from Python
- ‚ùå Confusion about Python vs agent tool calls

---

## ‚úÖ FIXED in v0.43.4: Agent Not Recognizing Python Success

**Status**: FIXED - Added explicit workflow example

**TRACE**: /home/mcstar/Nextcloud/VTCLLC/.trace/trace_20260107_174046.json

### Issue: Agent Thought Python Failed When It Succeeded

**What happened**:
- ‚úÖ PLANNER retry worked! Created correct 1-task plan on attempt 2
- ‚úÖ SHELL_EXECUTOR started execution
- ‚úÖ Python code ran successfully, outputted file paths
- ‚ùå Agent said: "directory variable wasn't properly recognized"
- ‚ùå Agent retried same Python code 5 times
- ‚ùå Hit circuit breaker at iteration 4 (5th loop)
- ‚ùå Never processed any files

**Root cause**:
Agent didn't understand the 2-step workflow:
1. Python outputs file paths ‚Üí Agent thought this was a failure
2. Agent should process each file ‚Üí Agent never got here

**Why agent was confused**:
- Python successfully ran and printed file paths
- But no explicit "SUCCESS" message
- Agent expected error or success indicator
- Saw file paths, thought "directory variable not recognized"
- Kept retrying the Python code instead of moving to Step 2

### Solution: Explicit Workflow Example

**Added to SHELL_EXECUTOR prompt** - Complete step-by-step example:

```
CORRECT APPROACH (what you MUST do):
1. Run Python/bash to list files
2. Python outputs file paths (ONE PER LINE)
3. YOU read the output - if you see file paths, IT WORKED!
4. For EACH file path in the output, call MCP tool
5. Done!

EXAMPLE CORRECT WORKFLOW:
Loop 0: Call Python to list files
  RESULT: /DIR/file1.pdf
          /DIR/file2.pdf
  YOU: ‚úÖ Python succeeded! I see 2 file paths.

Loop 1: Call pdf_extract.process_document(file_path='/DIR/file1.pdf')
Loop 2: Call pdf_extract.process_document(file_path='/DIR/file2.pdf')
  YOU: Done! All 2 files processed.

CRITICAL: Python output = file paths = SUCCESS!
```

**Also increased loop_limit**:
- Was: 5 iterations (too few for batch operations)
- Now: 15 iterations (enough for listing + processing multiple files)
- Example: 1 iteration to list + 7 iterations to process = 8 total

### Files Modified (v0.43.4):
- mcp_client_for_ollama/agents/definitions/shell_executor.json - Added explicit workflow
- mcp_client_for_ollama/__init__.py - Version 0.43.4
- pyproject.toml - Version 0.43.4
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:

**Loop 0**: Agent runs Python to list files
- Python outputs: `/home/.../file1.pdf\n/home/.../file2.pdf\n...`
- Agent sees file paths ‚Üí Recognizes SUCCESS!

**Loop 1**: Agent processes first file
- Calls: `pdf_extract.process_document(file_path='/home/.../file1.pdf')`

**Loop 2**: Agent processes second file
- Calls: `pdf_extract.process_document(file_path='/home/.../file2.pdf')`

**Loop N**: Agent finishes all files
- Reports: "Processed 7 files successfully"

**No more**:
- ‚ùå "directory variable not recognized" errors
- ‚ùå Retrying Python code in a loop
- ‚ùå Hitting circuit breaker before processing
- ‚ùå Confusion about whether Python succeeded

## ‚úÖ FIXED in v0.43.5: Multiple Issues Blocking File Processing

**Status**: FIXED - pdf_extract rebuilt, loop_limit increased

**TRACE**: /home/mcstar/Nextcloud/VTCLLC/.trace/trace_20260107_174855.json

### Issue #1: pdf_extract doc_type Error Still Occurring

**What happened**:
- Loop 4: Agent successfully listed files
- Loop 4: Called pdf_extract.process_document
- **ERROR**: "Processing error: local variable 'doc_type' referenced before assignment"
- This is the SAME error we supposedly fixed in v0.42.9!

**Root cause**:
The fix was committed to code but:
- pdf_extract MCP server wasn't rebuilt with the fix
- OR server wasn't restarted after rebuild
- Agent kept hitting the old buggy code

**Fix**:
‚úÖ Rebuilt pdf_extract package with doc_type fix
- The try/except wrapper is in the code
- Package rebuilt successfully
- **Server needs to be restarted for fix to take effect**

### Issue #2: Loop Limit Too Low for Batch Operations

**What happened**:
- Loop 0-3: Agent wasted loops on Python variable errors
- Loop 4: Listed files successfully
- Loop 4-8: Tried to process files, hit doc_type error each time
- Loop 9: Listed files again, then HIT LOOP LIMIT
- Result: **ZERO files processed**

**Root cause**:
- loop_limit was 15 (from v0.43.4)
- Needed: 1 to list + 7 to process = 8 minimum
- But with errors: Agent wasted ~5 loops on errors
- Then hit limit before finishing
- Not enough buffer for error recovery

**Fix**:
‚úÖ Increased loop_limit from 15 ‚Üí 20
- Allows for initial errors (3-4 loops)
- Plus file listing (1 loop)
- Plus processing 7 files (7 loops)
- Plus buffer for any doc_type errors (3-4 loops)
- Total: ~15-16 loops needed, 20 provides safety margin

### Issue #3: Python Variable Errors (Secondary)

**What happened**:
- Loop 0: Python code ran, but agent thought it failed
- Loop 1-3: Agent kept retrying with "typo" errors
- Loop 4: Finally succeeded

**Root cause**:
- Agent generated Python code with syntax issues
- Or misinterpreted Python output
- This was secondary to main doc_type issue

**Note**: This is less critical since v0.43.4 fixed the workflow understanding

### Critical Action Required

**‚ö†Ô∏è MUST RESTART pdf_extract MCP SERVER**:
```bash
# Kill existing server process
pkill -f "pdf_extract"

# Restart server (however it's configured to run)
# Usually something like:
python -m pdf_extract.mcp.server
# OR
uvicorn pdf_extract.mcp.server:app
```

Without restarting the server, the doc_type fix won't be active!

### Files Modified (v0.43.5):
- pdf_extract_mcp (rebuilt with doc_type fix)
- mcp_client_for_ollama/agents/definitions/shell_executor.json - Increased loop_limit to 20
- mcp_client_for_ollama/__init__.py - Version 0.43.5
- pyproject.toml - Version 0.43.5
- docs/qa_bugs.md - Documentation

### Expected Behavior After Server Restart:

**Loop 0-3**: Agent might have Python errors (working through them)

**Loop 4**: Agent lists files successfully
- Sees 7 file paths

**Loop 5**: Process file 1
- Calls pdf_extract.process_document(file_path='...')
- **NEW**: No doc_type error! Fix is active
- Returns: {success: true, doc_type: "receipt", ...}

**Loop 6-11**: Process files 2-7
- Each successful

**Loop 12**: Report complete
- "Successfully processed 7 PDF files"

**No more**:
- ‚ùå doc_type UnboundLocalError
- ‚ùå Hitting loop limit before processing
- ‚ùå Zero files processed


## ‚úÖ FIXED in v0.44.1: UI Form Not Shown - Wrong Agent Assignment

**Status**: FIXED - PLANNER now routes form requests correctly

**TRACE**: /home/mcstar/Nextcloud/DEV/pdf_extract_mcp/.trace/trace_20260110_170656.json

### Issue Summary

User asked: "create a form for inputing user name and profile information"

**What happened**:
1. PLANNER assigned task to TOOL_FORM_AGENT
2. TOOL_FORM_AGENT called `builtin.generate_tool_form` with invalid tool name "username_profile"
3. Tool call failed (no such tool exists)
4. Agent returned text describing a tool call instead of an artifact
5. NO FORM SHOWN TO USER

### Root Causes

**Cause 1: Wrong Agent Assignment**
- User requested a GENERIC data collection form
- PLANNER assigned to TOOL_FORM_AGENT (wrong!)
- TOOL_FORM_AGENT is specialized for creating forms FROM existing tool schemas
- Should have assigned to ARTIFACT_AGENT instead

**Cause 2: PLANNER Lacked Agent Guidance**
- PLANNER prompt listed basic agents but not ARTIFACT_AGENT or TOOL_FORM_AGENT
- No guidance on when to use each for form requests
- PLANNER couldn't distinguish between:
  - Generic form: "create a form for user profile" ‚Üí ARTIFACT_AGENT
  - Tool-based form: "create a form to use read_file tool" ‚Üí TOOL_FORM_AGENT

**Cause 3: Tool Call Failed Silently**
- TOOL_FORM_AGENT tried: `generate_tool_form(tool_name="username_profile")`
- "username_profile" is not a real MCP tool name
- Tool handler expected real tool like "builtin.read_file" or "pdf_extract.process_document"
- Error not properly handled, agent gave up

### Solution (v0.44.1)

**Fix 1: Updated PLANNER Agent List**
Added ARTIFACT_AGENT and TOOL_FORM_AGENT to planner.json with clear guidance:

```
ARTIFACT_AGENT - Create visualizations and generic data collection forms
  Use for: tables, charts, graphs, timelines, dashboards, GENERIC forms
  Example: "create a form for user profile" ‚Üí ARTIFACT_AGENT

TOOL_FORM_AGENT - Create forms FROM existing MCP tool schemas
  Use for: "create a form to use [tool_name]" OR "make [tool_name] easier to use"
  Example: "create a form to use read_file tool" ‚Üí TOOL_FORM_AGENT
  NEVER use for generic forms without a specific tool!
```

**Fix 2: Added Form Creation Examples to ARTIFACT_AGENT**
Updated artifact_agent.json with explicit generic form creation instructions:
- Complete form artifact structure
- All available field types (text, email, textarea, select, checkbox, etc.)
- Validation rules
- Submission configuration
- Clear distinction between artifact:form (generic) and artifact:toolform (tool-based)

### Files Modified (v0.44.1)
- mcp_client_for_ollama/agents/definitions/planner.json - Added agent routing guidance
- mcp_client_for_ollama/agents/definitions/artifact_agent.json - Added form examples
- docs/qa_bugs.md - Documentation

### Expected Behavior Now

**User**: "create a form for user profile information"

**PLANNER**: Assigns to ARTIFACT_AGENT (recognizes generic form request)

**ARTIFACT_AGENT**: Generates artifact:form with proper structure:
```artifact:form
{
  "type": "artifact:form",
  "version": "1.0",
  "title": "User Profile Form",
  "data": {
    "fields": [
      {"id": "username", "type": "text", "label": "Username", "required": true},
      {"id": "email", "type": "email", "label": "Email", "required": true},
      {"id": "bio", "type": "textarea", "label": "Bio"}
    ],
    "submission": {
      "method": "api",
      "endpoint": "/api/submit",
      "successMessage": "Saved!"
    }
  }
}
```

**Result**: Form artifact displayed in web UI

### Comparison: Generic vs Tool Forms

**Generic Form (ARTIFACT_AGENT)**:
- Request: "create a form for [arbitrary data]"
- Agent: ARTIFACT_AGENT
- Output: artifact:form
- No MCP tool involved

**Tool Form (TOOL_FORM_AGENT)**:
- Request: "create a form to use [tool_name]"
- Agent: TOOL_FORM_AGENT
- Output: artifact:toolform (auto-generated from tool schema)
- Executes actual MCP tool when submitted

## ‚úÖ FIXED in v0.44.2: Tool Form Agent - Artifact Not Returned

**Status**: FIXED - Tool handlers now return proper artifacts

**TRACE**: /home/mcstar/Nextcloud/DEV/pdf_extract_mcp/.trace/trace_20260110_190735.json

### Issue Summary

User asked: "create a form to use list-files"

**What happened**:
1. ‚úÖ PLANNER correctly assigned to TOOL_FORM_AGENT (v0.44.1 fix worked!)
2. ‚úÖ TOOL_FORM_AGENT called `builtin.generate_tool_form`
3. ‚ùå Tool call returned empty response in loop 0
4. ‚ùå Agent gave up and manually created JSON with ````json` fence in loop 1
5. ‚ùå NO FORM SHOWN TO USER (UI only detects ````artifact:type` fences)

### Root Causes

**Cause 1: Tool Handler Bug**
Line 3294 in builtin.py tried to access `artifact['data']['type']`:
```python
artifact_json = json.dumps(artifact['data'], indent=2)
return f"```artifact:{artifact['data']['type']...}"
```

But artifact structure has `type` at top level:
```python
{
  "type": "artifact:toolform",  # ‚Üê HERE, not in 'data'
  "data": { ... }
}
```

Result: KeyError on 'type', caught by try/except, returned "Error generating tool form: 'type'"

**Cause 2: Agent Didn't Output Tool Result**
- Agent called tool in loop 0
- Tool returned error string (not artifact)
- Agent saw error, didn't output anything (empty response)
- Loop 1: Agent tried to manually create form without using the tool
- Created ````json` fence instead of ````artifact:toolform`

**Cause 3: Missing Output Instructions**
- Agent didn't know it should directly output the tool's result
- No explicit instruction to pass through the artifact code block

### Solution (v0.44.2)

**Fix 1: Fixed Tool Handler Bug** (`builtin.py:3292-3296`)
Changed from accessing `artifact['data']['type']` to `artifact['type']`:
```python
# Return as formatted artifact code block
# Extract type from top level, not from data
artifact_type = artifact['type'].replace('artifact:', '')
artifact_json = json.dumps(artifact, indent=2)  # ‚Üê Dump full artifact
return f"```artifact:{artifact_type}\n{artifact_json}\n```"
```

Applied to all 4 artifact generation handlers:
- `_handle_generate_tool_form`
- `_handle_generate_query_builder`
- `_handle_generate_tool_wizard`
- `_handle_generate_batch_tool`

**Fix 2: Added Explicit Output Instructions** (`tool_form_agent.json`)
Added to agent prompt:
```
CRITICAL WORKFLOW:
1. Identify the tool name
2. Call builtin.generate_tool_form with that tool name
3. The tool returns a complete artifact code block
4. OUTPUT THAT ARTIFACT DIRECTLY - DO NOT modify it
5. DO NOT create your own JSON structure
6. JUST OUTPUT THE ARTIFACT the tool gave you
```

### Files Modified (v0.44.2)
- mcp_client_for_ollama/tools/builtin.py - Fixed artifact type access (4 handlers)
- mcp_client_for_ollama/agents/definitions/tool_form_agent.json - Added output instructions
- mcp_client_for_ollama/pyproject.toml - Version 0.44.2
- mcp_client_for_ollama/__init__.py - Version 0.44.2
- docs/qa_bugs.md - Documentation

### Expected Behavior Now

**User**: "create a form to use list_files"

**PLANNER**: Assigns to TOOL_FORM_AGENT ‚úÖ

**TOOL_FORM_AGENT Loop 0**:
- Calls `builtin.generate_tool_form(tool_name="builtin.list_files")`
- Tool returns:
  ````artifact:toolform
  {
    "type": "artifact:toolform",
    "version": "1.0",
    "title": "List Files",
    "data": {
      "tool_name": "builtin.list_files",
      "schema": { ... },
      "submit_button": {"label": "List", "icon": "list"}
    }
  }
  ```
- Agent outputs this artifact directly

**Result**: Form artifact displayed in web UI ‚úÖ

### Testing

Verified with:
```python
tool_manager._handle_generate_tool_form({"tool_name": "builtin.list_files"})
```

Returns proper ````artifact:toolform` code fence with complete artifact structure.

## ‚úÖ FIXED in v0.44.5: Tool Form Prefill Parameter Error + MCP Server Loading

**Status**: FIXED - Tool handler now parses JSON strings, user needs to restart web server

**TRACE**: /home/mcstar/Nextcloud/Vault/Journal/.trace/trace_20260110_212742.json

### Issue 1: Tool Form Not Displayed - prefill Parameter Error

**What happened**:
1. ‚úÖ PLANNER correctly assigned to TOOL_FORM_AGENT
2. ‚úÖ Agent called `builtin.generate_tool_form(tool_name="builtin.list_directories", prefill="{}")`
3. ‚ùå Tool handler crashed: `'str' object is not a mapping`
4. ‚ùå Agent gave up in loop 1 and manually created JSON without artifact fence
5. ‚ùå NO FORM SHOWN (UI only detects ```artifact:type fences)

**Root Cause**:
The LLM passed `prefill` as a JSON string `"{}"` instead of a dict object:
```json
"arguments": {"prefill": "{}", "tool_name": "builtin.list_directories"}
```

The tool handler expected a dict but got a string, causing the error when trying to use it as a mapping.

**Solution (v0.44.5)**:
Fixed `_handle_generate_tool_form` in builtin.py to parse JSON strings:
```python
# Parse prefill if it's a JSON string
if isinstance(prefill, str):
    try:
        prefill = json.loads(prefill) if prefill else None
    except json.JSONDecodeError:
        prefill = None
```

Now works with both:
- Dict: `prefill={"path": "/home"}`
- JSON string: `prefill='{"path": "/home"}'`
- Empty string: `prefill="{}"`

### Issue 2: MCP Servers Not Loading (User Action Required)

**What happened**:
Only builtin tools visible, no biblerag or obsidian tools despite v0.44.4 fix.

**Root Cause**:
The v0.44.4 fix is correct, but the web server needs to be restarted for it to take effect.

**Solution (v0.44.5)**:
The code is already fixed in v0.44.4. User must:
1. Stop the current web server (Ctrl+C)
2. Restart with config directory:
   ```bash
   python3 -m mcp_client_for_ollama web --config-dir /home/mcstar/Nextcloud/Vault/Journal/.config
   ```
3. Check console output for:
   ```
   Loaded config from: .../config.json
   Found 3 MCP server(s) in config
   ```

If still not working after restart:
- Verify config file exists: `ls -la /path/to/.config/config.json`
- Check file is readable
- Ensure mcpServers section is in the file

### Files Modified (v0.44.5):
- mcp_client_for_ollama/tools/builtin.py - Fixed prefill parameter parsing
- mcp_client_for_ollama/pyproject.toml - Version 0.44.5
- mcp_client_for_ollama/__init__.py - Version 0.44.5
- docs/qa_bugs.md - Documentation

### Expected Behavior After v0.44.5 + Server Restart:

**User**: "generate a form to input the tool call parameters for list-directories"

**PLANNER**: Assigns to TOOL_FORM_AGENT ‚úÖ

**TOOL_FORM_AGENT Loop 0**:
- Calls `builtin.generate_tool_form(tool_name="builtin.list_directories", prefill="{}")`
- Prefill gets parsed from string to dict ‚úÖ
- Tool returns proper artifact:
  ```artifact:toolform
  {
    "type": "artifact:toolform",
    "version": "1.0",
    "title": "List Directories",
    "data": {
      "tool_name": "builtin.list_directories",
      "schema": {...},
      "submit_button": {"label": "List", "icon": "list"}
    }
  }
  ```
- Agent outputs artifact directly ‚úÖ

**Result**: Form displayed in web UI ‚úÖ

**MCP Servers**: biblerag and obsidian tools now available ‚úÖ


## 0.44.5 issues
Trace: /home/mcstar/Nextcloud/Vault/Journal/.trace/trace_20260110_214045.json
- still no user form being shown by the UI
- between user queries, the ai/ui forgets the context of previous questions.
For instance, in the first query the user asked about the book of Luke in the Amplified version, the in the second question the user mentioned showing the 5th chapter of luke, and the AI ignored the context of the Amplified version and planned to use the KJV version instead.

## ‚úÖ FIXED in v0.44.6: Missing get_tool Method - Forms Not Generated

**Status**: FIXED - ToolManager now has get_tool method for MCP tools

**TRACE**: /home/mcstar/Nextcloud/Vault/Journal/.trace/trace_20260110_214045.json

### Issue Summary

User asked: "create a user form for calling Get Topic Verses"

**What happened**:
1. ‚úÖ PLANNER correctly assigned to TOOL_FORM_AGENT
2. ‚úÖ TOOL_FORM_AGENT called `builtin.generate_tool_form(tool_name="biblerag.get_topic_verses")`
3. ‚ùå Tool handler returned: "Error: Tool not found: biblerag.get_topic_verses"
4. ‚ùå Agent retried multiple times, all failed with same error
5. ‚ùå NO FORM SHOWN TO USER

### Root Cause

**Missing Method in ToolManager**:
- `ToolSchemaParser` expects `ToolManager.get_tool(tool_name)` method (line 252-253 in tool_schema_parser.py)
- `ToolManager` class had NO `get_tool` method
- When trying to generate form for MCP tool ‚Üí Can't find tool ‚Üí Returns "Tool not found"
- Only builtin tools could be found through the fallback `get_builtin_tools()` path

**Why This Happened**:
- ToolManager stores all tools (builtin + MCP) in `available_tools` list
- But had no method to retrieve a single tool by name
- ToolSchemaParser was designed to call `get_tool(tool_name)`
- Missing method meant ALL MCP tool forms would fail

### Solution (v0.44.6)

**Added get_tool Method to ToolManager** (manager.py:146-162):
```python
def get_tool(self, tool_name: str) -> Optional[Dict]:
    """Get a specific tool by name.

    Args:
        tool_name: Name of the tool to retrieve

    Returns:
        Dictionary with tool metadata (name, description, inputSchema) or None if not found
    """
    for tool in self.available_tools:
        if tool.name == tool_name:
            return {
                'name': tool.name,
                'description': tool.description,
                'inputSchema': tool.inputSchema
            }
    return None
```

**How It Works**:
1. Searches through `self.available_tools` list
2. Finds tool with matching name
3. Returns dict with name, description, inputSchema
4. Returns None if not found

**Now Works For**:
- ‚úÖ All builtin tools (builtin.*)
- ‚úÖ All MCP server tools (biblerag.*, obsidian.*, etc.)
- ‚úÖ Any tool in available_tools list

### Files Modified (v0.44.6):
- mcp_client_for_ollama/tools/manager.py - Added get_tool method
- mcp_client_for_ollama/pyproject.toml - Version 0.44.6
- mcp_client_for_ollama/__init__.py - Version 0.44.6
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:

**User**: "create a form to use biblerag.get_topic_verses"

**PLANNER**: Assigns to TOOL_FORM_AGENT ‚úÖ

**TOOL_FORM_AGENT Loop 0**:
- Calls `builtin.generate_tool_form(tool_name="biblerag.get_topic_verses")`
- ToolSchemaParser calls `tool_manager.get_tool("biblerag.get_topic_verses")` ‚úÖ
- **NEW**: Method exists! Returns tool metadata ‚úÖ
- Generates artifact:
  ```artifact:toolform
  {
    "type": "artifact:toolform",
    "version": "1.0",
    "title": "Get Topic Verses",
    "data": {
      "tool_name": "biblerag.get_topic_verses",
      "schema": {...},
      "submit_button": {"label": "Search", "icon": "search"}
    }
  }
  ```
- Agent outputs artifact ‚úÖ

**Result**: Form displayed in web UI ‚úÖ

### Testing Required:
1. Restart web server with updated code
2. Ask: "create a form to use biblerag.get_topic_verses"
3. Verify form is generated and displayed
4. Test with other MCP tools (obsidian.*, etc.)

## ‚úÖ FIXED in v0.45.0: Context Not Preserved Between Queries

**Status**: FIXED - Chat history now properly passed to MCP client

**TRACE**: /home/mcstar/Nextcloud/Vault/Journal/.trace/trace_20260110_214045.json

### Issue Summary

Between user queries, the AI forgets the context of previous questions.

**Example**:
- Query 1: "Show me the book of Luke in the Amplified version"
- Query 2: "Show me the 5th chapter of Luke"
- Expected: AI remembers to use Amplified version from Query 1
- Actual: AI uses KJV version (default), ignoring the Amplified context

### Root Cause

**Fresh MCP Client Without History**:
- WebMCPClient creates a **fresh MCP client for each request** (client_wrapper.py:171)
- Reason: Avoids event loop binding issues in Flask async context
- Problem: Fresh client has **empty chat_history**
- The delegation system receives `mcp_client.chat_history` which is always empty (line 218)

**WebMCPClient Has Two Histories**:
1. `self.chat_history` - Persistent across all requests in the session ‚úÖ
2. `mcp_client.chat_history` - Fresh/empty for each request ‚ùå

**Flow**:
```
User Query 1 ‚Üí Fresh MCP client (empty history) ‚Üí Response ‚Üí Saved to self.chat_history
User Query 2 ‚Üí Fresh MCP client (empty history) ‚Üí Response ‚Üí Context from Query 1 LOST!
```

### Solution (v0.45.0)

**Copy Persistent History to Fresh MCP Client** (client_wrapper.py:174-178):
```python
if mcp_client:
    # Add previous conversation history to the fresh MCP client
    # This ensures context is maintained across requests
    if self.chat_history:
        # Copy our persistent chat history to the fresh MCP client
        mcp_client.chat_history = self.chat_history.copy()
```

**How It Works**:
1. WebMCPClient maintains persistent `self.chat_history` for the session
2. When creating fresh MCP client for new request:
   - Copy all previous messages from `self.chat_history`
   - Fresh client now has full conversation context
3. Delegation system receives `mcp_client.chat_history` with complete history ‚úÖ
4. After response, append to `self.chat_history` for next request

**Flow After Fix**:
```
User Query 1 ‚Üí Fresh MCP client (empty) ‚Üí Response ‚Üí Saved to self.chat_history
User Query 2 ‚Üí Fresh MCP client (COPY of self.chat_history) ‚Üí Response with context ‚úÖ
```

### Files Modified (v0.45.0):
- mcp_client_for_ollama/web/integration/client_wrapper.py - Copy history to fresh client
- mcp_client_for_ollama/pyproject.toml - Version 0.45.0
- mcp_client_for_ollama/__init__.py - Version 0.45.0
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:

**User Query 1**: "Show me the book of Luke in the Amplified version"
- MCP client has empty history
- AI responds with Luke from Amplified version
- Response saved to `self.chat_history`

**User Query 2**: "Show me the 5th chapter of Luke"
- Fresh MCP client created
- **NEW**: `self.chat_history` copied to `mcp_client.chat_history` ‚úÖ
- PLANNER sees previous query about Amplified version ‚úÖ
- AI correctly uses Amplified version for chapter 5 ‚úÖ

**Result**: Context preserved across all queries in session ‚úÖ

### Testing Required:
1. Restart web server with updated code
2. Start a new conversation
3. Query 1: Ask about "Luke in Amplified version"
4. Query 2: Ask about "chapter 5 of Luke" (without specifying version)
5. Verify AI remembers to use Amplified version from Query 1

### Summary of v0.45.0 Fixes

This release includes TWO critical fixes:

**Fix 1 (v0.44.6): Missing get_tool Method**
- Added `ToolManager.get_tool()` method
- Now MCP tools can be found by ToolSchemaParser
- Forms for MCP tools now work ‚úÖ

**Fix 2 (v0.45.0): Context Not Preserved**
- Copy persistent chat history to fresh MCP client
- Conversation context now maintained across queries ‚úÖ

Both issues are now resolved!


## 0.45.0 Issues:
Trace: /home/mcstar/Nextcloud/Vault/Journal/.trace/trace_20260111_121256.json
- TOOL_FORM_AGENT unable to find loaded tools. The tool biblerag.get_topic_verses is not found by the agent even though it's shown in the UI
- no ui shown for the form requested

## ‚úÖ FIXED in v0.45.1: BuiltinToolManager Can't Find MCP Tools

**Status**: FIXED - BuiltinToolManager now has reference to parent ToolManager

**TRACE**: /home/mcstar/Nextcloud/Vault/Journal/.trace/trace_20260111_121256.json

### Issue Summary

TOOL_FORM_AGENT unable to find loaded MCP tools when generating forms.

**What happened**:
1. ‚úÖ User can see biblerag.get_topic_verses in the UI (tool is loaded)
2. ‚úÖ User asks "create a form to use biblerag.get_topic_verses"
3. ‚úÖ PLANNER assigns to TOOL_FORM_AGENT
4. ‚úÖ TOOL_FORM_AGENT calls `builtin.generate_tool_form(tool_name="biblerag.get_topic_verses")`
5. ‚ùå Tool handler returns: "Error: Tool not found: biblerag.get_topic_verses"
6. ‚ùå NO FORM GENERATED
7. ‚ùå No UI shown for the form requested

### Root Cause

**BuiltinToolManager Isolated from MCP Tools**:
- v0.44.6 added `get_tool()` method to `ToolManager` ‚úÖ
- `ToolSchemaParser` calls `tool_manager.get_tool(tool_name)` (line 252-253 in tool_schema_parser.py)
- Problem: `tool_manager` is a `BuiltinToolManager` instance, NOT the main `ToolManager`

**Architecture Before Fix**:
```
ToolManager (has ALL tools: builtin + MCP)
  ‚îî‚îÄ BuiltinToolManager (only knows builtin tools)
       ‚îî‚îÄ When generating form, passes `self` to ToolSchemaParser
            ‚îî‚îÄ ToolSchemaParser can only find builtin tools ‚ùå
```

**Why This Happened**:
- `BuiltinToolManager` is instantiated by `ToolManager` (manager.py:41-46)
- But `BuiltinToolManager` had no reference back to parent
- When artifact generation tools run, they pass `self` (BuiltinToolManager) to ToolSchemaParser
- BuiltinToolManager.get_builtin_tools() only returns builtin tools
- Has no method to access MCP tools from parent ToolManager
- Result: MCP tools appear "not found" even though they're loaded

### Solution (v0.45.1)

**Step 1: Add Parent Reference to BuiltinToolManager** (builtin.py:14-32)

Added `parent_tool_manager` parameter to `__init__`:
```python
def __init__(self, model_config_manager: Any, ollama_host: str = None,
             config_manager: Any = None, console: Optional[Console] = None,
             parent_tool_manager: Any = None):
    """
    Args:
        parent_tool_manager: Optional reference to parent ToolManager (for accessing MCP tools).
    """
    # ... other init code ...
    self.parent_tool_manager = parent_tool_manager  # Reference to parent ToolManager
```

**Step 2: Pass Parent Reference from ToolManager** (manager.py:41-46)

When creating BuiltinToolManager, pass `self`:
```python
self.builtin_tool_manager = BuiltinToolManager(
    self.model_config_manager,
    config_manager=self.config_manager,
    console=self.console,
    parent_tool_manager=self  # Pass reference to parent ToolManager
)
```

**Step 3: Use Parent ToolManager in Artifact Handlers** (builtin.py:3290-3293, 3321-3323, 3363-3365, 3396-3398)

Updated all 4 artifact generation handlers to use parent when available:
```python
# Initialize parser with parent tool manager (has all tools) if available, otherwise self
# This allows ToolSchemaParser to find both builtin and MCP tools
tool_manager = self.parent_tool_manager if self.parent_tool_manager else self
parser = ToolSchemaParser(tool_manager=tool_manager)
```

Applied to:
- `_handle_generate_tool_form`
- `_handle_generate_query_builder`
- `_handle_generate_tool_wizard`
- `_handle_generate_batch_tool`

**Architecture After Fix**:
```
ToolManager (has ALL tools: builtin + MCP)
  ‚Üï (bidirectional reference)
BuiltinToolManager (has parent_tool_manager reference)
  ‚îî‚îÄ When generating form, passes parent_tool_manager to ToolSchemaParser
       ‚îî‚îÄ ToolSchemaParser can find ALL tools (builtin + MCP) ‚úÖ
```

### Files Modified (v0.45.1):
- mcp_client_for_ollama/tools/builtin.py - Added parent_tool_manager parameter and updated 4 handlers
- mcp_client_for_ollama/tools/manager.py - Pass self as parent_tool_manager
- mcp_client_for_ollama/pyproject.toml - Version 0.45.1
- mcp_client_for_ollama/__init__.py - Version 0.45.1
- docs/qa_bugs.md - Documentation

### Expected Behavior Now:

**User**: "create a form to use biblerag.get_topic_verses"

**PLANNER**: Assigns to TOOL_FORM_AGENT ‚úÖ

**TOOL_FORM_AGENT Loop 0**:
- Calls `builtin.generate_tool_form(tool_name="biblerag.get_topic_verses")`
- Handler uses `self.parent_tool_manager` (the main ToolManager) ‚úÖ
- ToolSchemaParser calls `parent_tool_manager.get_tool("biblerag.get_topic_verses")` ‚úÖ
- **NEW**: Parent ToolManager has MCP tools! Returns tool metadata ‚úÖ
- Generates artifact with proper schema
- Agent outputs artifact ‚úÖ

**Result**: Form displayed in web UI side panel ‚úÖ

### Testing Required:
1. Restart web server with updated code
2. Ask: "create a form to use biblerag.get_topic_verses"
3. Verify form is generated and displayed in side panel
4. Test with other MCP tools (obsidian.obsidian_list_files_in_dir, etc.)

### Summary of All Fixes (v0.44.6 ‚Üí v0.45.1)

**v0.44.6: Added get_tool Method**
- ToolManager.get_tool() added to find tools by name
- But BuiltinToolManager couldn't access it ‚ùå

**v0.45.0: Context Preservation**
- Fixed conversation history not persisting between queries ‚úÖ

**v0.45.1: BuiltinToolManager Access to MCP Tools**
- BuiltinToolManager now references parent ToolManager
- Can access ALL tools (builtin + MCP) when generating forms ‚úÖ
- All artifact generation handlers updated ‚úÖ

All form generation issues now resolved!
